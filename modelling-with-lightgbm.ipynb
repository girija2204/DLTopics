{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import LabelEncoder","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset = pd.read_csv(\"../input/tabular-playground-series-feb-2021/train.csv\")\ntest_dataset = pd.read_csv(\"../input/tabular-playground-series-feb-2021/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"train_dataset.isnull().any()\ntest_dataset.isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.value_counts(train_dataset['cat0'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def convert_to_categorical(train_dataset, test_dataset):\n    cat_cols = train_dataset.columns[1:11]\n    for col in cat_cols:\n        le = LabelEncoder()\n        le.fit(train_dataset[col])\n        \n        train_dataset[col]=le.transform(train_dataset[col])\n        test_dataset[col]=le.transform(test_dataset[col])\n    return train_dataset, test_dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset, test_dataset = convert_to_categorical(train_dataset, test_dataset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset.drop(['id'],axis=1,inplace=True)\ntest_dataset.drop(['id'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def scatter_plot(x,y,c=None,cmap=None):\n    plt.rcParams.update({'figure.figsize':(10,8),'figure.dpi':100})\n    plt.scatter(x['values'],y['values'],c=c,cmap=cmap])\n    plt.title(f\"Correlation between: {x['name']} - {y['name']}\")\n    plt.xlabel(f\"{x['name']}\")\n    plt.ylabel(f\"{y['name']}\")\n    if cmap is not None: plt.colorbar() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = {'name': \"cont0\", 'values': train_dataset['cont0']}\ny = {'name': \"target\", \"values\": train_dataset['target']}\nscatter_plot(x,y,train_dataset['target'],\"Spectral\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Before moving on further, let's see if the input variables are correlated with one another. We will plot the heatmap for all the variables."},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.stats import pearsonr\npearsonr(train_dataset.loc[:,'cont13'], train_dataset.loc[:,'cont6'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams.update({'figure.figsize':(15,20),'figure.dpi':100})\nfig, (ax1,ax2) = plt.subplots(2,1)\nsns.heatmap(train_dataset.iloc[:,10:].corr(), annot=True, cbar_kws={\"orientation\": \"horizontal\"}, fmt='.1f', cmap='coolwarm', robust=True, ax=ax1)\nsns.heatmap(test_dataset.iloc[:,10:].corr(), annot=True, cbar_kws={\"orientation\": \"horizontal\"}, fmt='.1f', cmap='coolwarm', robust=True, ax=ax2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Heatmap for both the training and testing dataset have been plotted here. The behaviour seems similar in both the cases. That means the data in training and the testing dataset are in the same distribution. So not much to worry about them."},{"metadata":{},"cell_type":"markdown","source":"My plan was to remove certain variables from the input variables set, whose correlation exceeds a higher value like 0.8. But here it seems the highest correlation value between the variables is only 0.7. So now I don't think there is any point of removing one of these variables."},{"metadata":{},"cell_type":"markdown","source":"Most of the categorical variables have correlation 0 with any other variable. I think except cat5 and cat7, other categorical variables have 0 correlation. Even cat5, and cat7 shows 0 correlation with some variables. But we will pick these variables and see how they behave. I'm picking the pairs, cat5 and cont12, cat5 and cont5, as these pairs have higher correlation 0.7 and 0.6. Next, I'm gonna plot the scatter plot of these with the target variable."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.jointplot(data=train_dataset, x='cat4', y='target')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import scipy.stats as stats\nstats.pointbiserialr(train_dataset.loc[:,'cat5'], train_dataset.loc[:,'cont5'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"\nfor i in range(0,13):\n    sns.jointplot(data=train_dataset, x=f'cont{i}', y='target', hue='cat5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"sns.jointplot(data=train_dataset, x='cont12', y='target', hue='cat5')\nsns.jointplot(data=train_dataset, x='cont5', y='target', hue='cat5')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here I'm plotting the joint plots, i.e. a scatter plot of the continuous variable with the target variable, with also their frequency distributions. I've also added the categorical variable into the scene, to be able to see the relation between 3 variables at a time. The colors on the plot represent the categories. For ex. the points with high cont12 values belong to 2 and 3 for cat5 variable, whereas lower cont12 values belongs to 0 or 1 categories. This shows that there is a trend or a pattern between the two variables (cat5 and cont12). A similar behaviour is also found for the other pair, i.e. cont5 and cat5 plotted next."},{"metadata":{},"cell_type":"markdown","source":"The plots above also show the frequency distributions of the variables. For cont12, it seems most of the values lie in the range of 0.2-0.4, where for cont5, most of the values lie in the range of 0.2-0.6. Let's also confirm this by the value counts method."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset[(train_dataset['cont12']>0.2)&\n              (train_dataset['cont12']<0.4)].shape # almost 50% of the records in the train dataset lies in the range of 0.2 to 0.4 for cont12 variable.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, ax = plt.subplots(figsize=(10,7))\nsns.distplot(train_dataset['target'])\nax.xaxis.grid(False)\nax.set(ylabel=\"values\")\nax.set(xlabel=\"target\")\nax.set(title=\"target distribution\")\nsns.despine(trim=True, left=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train_dataset.columns[10:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax = plt.subplots(5,3,figsize=(20,20))\nfor index, feature in enumerate(train_dataset.columns[10:24]):\n    plt.subplot(5,3,index+1)\n    sns.histplot(train_dataset[feature],color=\"blue\",kde=True,label=\"train\")\n    sns.histplot(test_dataset[feature],color=\"red\",kde=True,label=\"test\")\n    plt.xlabel(feature)\n    plt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = train_dataset.iloc[:,10:24].corr()\nplt.subplots(figsize=(10,10))\nsns.heatmap(corr,cmap=\"Blues\",square=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# to check outliers\nfor col in train_dataset.columns[10:24]:\n    plt.boxplot([train_dataset[col],test_dataset[col]], labels=['train','test'])\n    plt.title(col)\n    plt.legend()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.boxplot(train_dataset['target'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def replace_outliers(data):\n    for col in data.columns[10:]:\n        Q1 = data[col].quantile(0.25)\n        Q3 = data[col].quantile(0.75)\n        IQR = Q3 - Q1\n        median_ = data[col].median()\n        data.loc[((data[col] < Q1 - 1.5*IQR) | (data[col] > Q3 + 1.5*IQR)), col] = median_\n    return data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset = replace_outliers(train_dataset)\ntest_dataset = replace_outliers(test_dataset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"# to check outliers\nfor col in train_dataset.columns[10:24]:\n    plt.boxplot([train_dataset[col],test_dataset[col]], labels=['train','test'])\n    plt.title(col)\n    plt.legend()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"fig,ax = plt.subplots(5,3,figsize=(20,20))\nfor index, feature in enumerate(train_dataset.columns[10:24]):\n    plt.subplot(5,3,index+1)\n    sns.histplot(train_dataset[feature],color=\"blue\",kde=True,label=\"train\")\n    sns.histplot(test_dataset[feature],color=\"red\",kde=True,label=\"test\")\n    plt.xlabel(feature)\n    plt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, ax = plt.subplots(figsize=(10, 8))\nsns.distplot(train_dataset['target'], color=\"b\")\nax.xaxis.grid(False)\nax.set(ylabel=\"Values\")\nax.set(xlabel=\"Target\")\nsns.despine(trim=True, left=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import lightgbm as lgb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train_dataset.iloc[:,:-1]\nY = train_dataset.iloc[:, -1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.2, random_state=22)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"LGB = lgb.LGBMRegressor(random_state=33, n_estimators=4800, min_data_per_group=5, boosting_type='gbdt',\n num_leaves=246, max_dept=-1, learning_rate=0.005, subsample_for_bin=200000,\n lambda_l1= 1.074622455507616e-05, lambda_l2= 2.0521330798729704e-06, n_jobs=-1, cat_smooth=1.0, \n importance_type='split', metric='rmse', min_child_samples=20, min_gain_to_split=0.0, feature_fraction=0.5, \n bagging_freq=6, min_sum_hessian_in_leaf=0.001, min_data_in_leaf=100, bagging_fraction=0.82063411)\n\nLGB.fit(X_train, Y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_LGB = LGB.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mse = np.sqrt(mean_squared_error(Y_test, pred_LGB))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mse","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_pred = LGB.predict(test_dataset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test1_dataset = pd.read_csv(\"../input/tabular-playground-series-feb-2021/test.csv\")\noutput = pd.DataFrame({'id':test1_dataset.id, 'target':test_pred})\noutput.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!kaggle competitions submit -c tabular-playground-series-feb-2021 -f submission.csv -m \"Message\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}